{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd468f22",
   "metadata": {},
   "source": [
    "\n",
    "# Object Detection Controlled Car\n",
    "\n",
    "This notebook demonstrates using object detection from a camera stream to control a remote car. By employing a pre-trained YOLO model for object detection and processing the video stream, specific objects can trigger car movements or actions.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75928ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import socket\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68c353",
   "metadata": {},
   "source": [
    "\n",
    "## Loading Class Names and YOLO Model\n",
    "\n",
    "We begin by loading the class names from COCO dataset and initializing the YOLO model with the pre-trained weights and configuration.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1992527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classNames = []\n",
    "with open('utils/resources/coco.names', 'r') as f:\n",
    "    classNames = f.read().splitlines()\n",
    "\n",
    "model = 'utils/resources/yolov3.weights'\n",
    "config = 'utils/resources/yolov3.cfg'\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f58e8",
   "metadata": {},
   "source": [
    "\n",
    "## Car Control Interface Configuration\n",
    "\n",
    "Next, we configure the car's control interface by setting the IP and port for communication.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa397b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IP = \"192.168.4.1\"\n",
    "PORT = 100\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67ae47",
   "metadata": {},
   "source": [
    "\n",
    "## Function for Sending Commands to the Car\n",
    "\n",
    "This function packages and sends control commands to the car via a TCP socket connection.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7699754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def send_command(command):\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "        sock.connect((IP, PORT))\n",
    "        sock.sendall(json.dumps(command).encode())\n",
    "        time.sleep(0.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55728251",
   "metadata": {},
   "source": [
    "\n",
    "## Processing the Camera Stream for Object Detection\n",
    "\n",
    "We process frames from the camera stream to detect objects using the YOLO model. Detected objects can then be used to make decisions on how to control the car's movements.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c473f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "session = requests.Session()\n",
    "response = session.get(stream_url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    bytes_data = bytes()\n",
    "    while True:\n",
    "        chunk = response.raw.read(1024)\n",
    "        if not chunk:\n",
    "            break\n",
    "        bytes_data += chunk\n",
    "        a = bytes_data.find(b'ÿØ')\n",
    "        b = bytes_data.find(b'ÿÙ')\n",
    "        while a != -1 and b != -1:\n",
    "            jpg = bytes_data[a:b+2]\n",
    "            bytes_data = bytes_data[b+2:]\n",
    "            img = cv2.imdecode(np.frombuffer(jpg, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if img is not None:\n",
    "                blob = cv2.dnn.blobFromImage(img, 1 / 255, (320, 320), (0, 0, 0), crop=False)\n",
    "                net.setInput(blob)\n",
    "                layerNames = net.getLayerNames()\n",
    "                outputNames = [layerNames[i-1] for i in net.getUnconnectedOutLayers()]\n",
    "                outputs = net.forward(outputNames)\n",
    "                # Object Detection Logic and Command Sending\n",
    "\n",
    "                cv2.imshow('Elegoo Smart Car Camera Stream', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            a = bytes_data.find(b'ÿØ')\n",
    "            b = bytes_data.find(b'ÿÙ')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9703c2",
   "metadata": {},
   "source": [
    "\n",
    "## Student Exercises\n",
    "\n",
    "1. **Implement Object Detection Logic**: Complete the object detection logic to identify specific objects within the video frames. Use the detected objects to decide on the car's movements.\n",
    "\n",
    "2. **Dynamic Command Decisions**: Based on the detected objects and their positions or sizes, dynamically adjust the commands sent to the car.\n",
    "\n",
    "3. **Integrate Multiple Object Detection**: Enhance the control logic to handle multiple objects detection simultaneously and prioritize or combine commands accordingly.\n",
    "\n",
    "4. **Feedback Mechanism**: Explore ways to provide feedback to the user about the detected objects and the car's response to those detections.\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
